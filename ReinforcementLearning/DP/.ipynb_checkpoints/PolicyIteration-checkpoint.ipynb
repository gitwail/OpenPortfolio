{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb5f3e73-b5e3-4160-9852-5cb21516c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pygame\n",
    "sys.path.append(\"../lib/myenv\")\n",
    "from gridworld import gridworld\n",
    "import numpy as np \n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "# sample from categorical distribution\n",
    "def sample_categorical(probabilities):\n",
    "    return random.choices(range(len(probabilities)), probabilities)[0]\n",
    "\n",
    "# gridworld dimension\n",
    "dim=10\n",
    "# gamma discounting factor \n",
    "gamma=1\n",
    "\n",
    "# delta for policy evaluation\n",
    "delta=0\n",
    "\n",
    "#env variable \n",
    "gw=gridworld(dim)\n",
    "\n",
    "# The agent is placed at (0,0) and value function are initiliazed to a zero array\n",
    "gw.reset()\n",
    "\n",
    "# State value (V) is an array of dimension nxn where n is the gridworld size\n",
    "V=np.random.rand(dim,dim)\n",
    "\n",
    "#Transition matrix\n",
    "Pss=np.ones((dim,dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "706eaa1a-cd21-400c-a856-5cf6e2f7e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def policy(dim):\n",
    "    \"\"\"\n",
    "    Initial policy with 1/4 chance for each action\n",
    "    Input: dimension of gridworld\n",
    "    output: random uniform policy\n",
    "    \"\"\"\n",
    "    pi={}\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            pi[(i,j)]=[0.25]*4\n",
    "\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f55edf00-80c6-4352-8260-fd6fb67461bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): [0.25, 0.25, 0.25, 0.25],\n",
       " (0, 1): [0.25, 0.25, 0.25, 0.25],\n",
       " (0, 2): [0.25, 0.25, 0.25, 0.25],\n",
       " (0, 3): [0.25, 0.25, 0.25, 0.25],\n",
       " (0, 4): [0.25, 0.25, 0.25, 0.25]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial policy\n",
    "\n",
    "# The action mapping for human readibility\n",
    "# 0:right\n",
    "# 1:Left\n",
    "# 2:UP\n",
    "# 3:Down \n",
    "\n",
    "pi=policy(dim)\n",
    "sliced_policy = dict(list(pi.items())[:5])\n",
    "sliced_policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26cbb505-fd98-45ce-af23-48a88e849e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation(pi,V,iteration_num=1):\n",
    "    delta=0\n",
    "    #looping over all states\n",
    "    for _ in range(iteration_num):\n",
    "        Vc=V.copy()\n",
    "        for i in range(dim):\n",
    "            for j in range(dim):\n",
    "                gw.reset()\n",
    "                listupdate=[]\n",
    "                gw.agent=(i,j)\n",
    "\n",
    "                if (i,j)!=(0,0):\n",
    "                   for a in range(4):\n",
    "                        o,r,_,_,_,=gw.step(a)\n",
    "                        k,l=o[:2]\n",
    "                        listupdate.append(pi[(i,j)][a]*(r+(gamma*Vc[k,l])))\n",
    "                    \n",
    "                   #update Vk+1\n",
    "                   Vc[i,j]=np.mean(listupdate)\n",
    "                #calculate delta\n",
    "                # print(\"state: \",(i,j))\n",
    "                # print(\"V\",V[i,j])\n",
    "                # print(\"Vc\",Vc[i,j])\n",
    "                # print(\"Vc-V\",np.abs(Vc[i,j]-V[i,j]))\n",
    "                # delta=max(delta,np.abs(V[i,j]-Vc[i,j]))\n",
    "                # print(\"delta \",delta)\n",
    "\n",
    "        \n",
    "        V=Vc\n",
    "        # if delta <0.1:\n",
    "        #     break\n",
    "\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2afe247-dcac-4c30-a068-931329108585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(Vpi):\n",
    "# policy iteration \n",
    "    for i in range(dim):\n",
    "                for j in range(dim):\n",
    "                    listofall=[-100]*4\n",
    "                    r=-1\n",
    "                    if (i,j)==gw.target:\n",
    "                        r=0\n",
    "                    \n",
    "                    # listofall=[Vpi[i+1,j],Vpi[i-1,j],Vpi[i,j-1],Vpi[i,j+1]]\n",
    "                    if i+1<dim:\n",
    "                        listofall[0]=pi[(i,j)][0]*(r+(gamma*Vpi[i+1,j]))\n",
    "                    if j+1<dim:\n",
    "                        listofall[3]=pi[(i,j)][3]*(r+(gamma*Vpi[i,j+1])) \n",
    "                    if i-1>dim:\n",
    "                        listofall[1]=pi[(i,j)][1]*(r+(gamma*Vpi[i-1,j]))\n",
    "                    if j-1>dim:\n",
    "                        listofall[2]=pi[(i,j)][1]*(r+(gamma*Vpi[i,j-1]))\n",
    "\n",
    "\n",
    "                    a=np.argmax(listofall)\n",
    "\n",
    "                    pi[(i,j)]=[1 if i == a else 0 for i in range(4)]\n",
    "\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5490d46-36e9-43c6-90cb-7dc3d5f1775d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########### Iteration number:  1\n",
      "[[ 0.87910427 -1.33892215 -1.57983001 -1.72380082 -1.95321862 -1.88870627\n",
      "  -1.76857352 -1.91548546 -1.83010733 -1.81594353]\n",
      " [-1.16692839 -1.44192906 -1.93203618 -2.04895334 -2.21689326 -2.17111285\n",
      "  -2.09556968 -2.14647589 -2.16708181 -2.11354116]\n",
      " [-1.41136482 -1.65764338 -1.97630961 -2.08995988 -2.09298425 -2.09374949\n",
      "  -2.05719202 -1.92292051 -2.2143732  -2.01693958]\n",
      " [-1.44185814 -1.50719522 -1.7526857  -2.01095664 -2.0646005  -2.02535232\n",
      "  -2.06031137 -1.96194832 -2.22249245 -2.03187636]\n",
      " [-1.53090027 -1.56577912 -1.82363828 -2.02241581 -2.14241401 -2.04406139\n",
      "  -2.22179289 -2.15745873 -2.18459051 -2.10426593]\n",
      " [-1.54374329 -1.49132038 -1.86621349 -2.07097835 -2.29316298 -2.19372172\n",
      "  -2.40811524 -2.37221743 -2.2712458  -2.15953089]\n",
      " [-1.43811815 -1.33305849 -1.80802239 -2.10043121 -2.20410922 -2.18166003\n",
      "  -2.32502538 -2.27500612 -2.32341188 -2.26978335]\n",
      " [-1.52049275 -1.30578927 -1.774745   -2.18471687 -2.15600851 -2.26058862\n",
      "  -2.22689041 -2.01663028 -2.10474858 -2.29967497]\n",
      " [-1.78017101 -1.86202876 -2.28012834 -2.43894251 -2.42194144 -2.60710879\n",
      "  -2.47813762 -2.1983295  -2.28865917 -2.08757363]\n",
      " [-2.6906731  -2.87008104 -2.98306889 -3.19018251 -3.18412106 -3.34305356\n",
      "  -3.29282014 -3.03611381 -3.0636051  -2.69572058]]\n",
      "{(0, 0): [1, 0, 0, 0], (0, 1): [1, 0, 0, 0], (0, 2): [0, 0, 0, 1], (0, 3): [0, 0, 0, 1], (0, 4): [0, 0, 0, 1], (0, 5): [0, 0, 0, 1], (0, 6): [0, 0, 0, 1], (0, 7): [0, 0, 0, 1], (0, 8): [0, 0, 0, 1], (0, 9): [1, 0, 0, 0], (1, 0): [1, 0, 0, 0], (1, 1): [1, 0, 0, 0], (1, 2): [1, 0, 0, 0], (1, 3): [1, 0, 0, 0], (1, 4): [1, 0, 0, 0], (1, 5): [1, 0, 0, 0], (1, 6): [1, 0, 0, 0], (1, 7): [1, 0, 0, 0], (1, 8): [0, 0, 0, 1], (1, 9): [1, 0, 0, 0], (2, 0): [1, 0, 0, 0], (2, 1): [1, 0, 0, 0], (2, 2): [1, 0, 0, 0], (2, 3): [1, 0, 0, 0], (2, 4): [1, 0, 0, 0], (2, 5): [1, 0, 0, 0], (2, 6): [0, 0, 0, 1], (2, 7): [1, 0, 0, 0], (2, 8): [0, 0, 0, 1], (2, 9): [1, 0, 0, 0], (3, 0): [0, 0, 0, 1], (3, 1): [1, 0, 0, 0], (3, 2): [1, 0, 0, 0], (3, 3): [1, 0, 0, 0], (3, 4): [0, 0, 0, 1], (3, 5): [1, 0, 0, 0], (3, 6): [0, 0, 0, 1], (3, 7): [1, 0, 0, 0], (3, 8): [0, 0, 0, 1], (3, 9): [1, 0, 0, 0], (4, 0): [1, 0, 0, 0], (4, 1): [1, 0, 0, 0], (4, 2): [1, 0, 0, 0], (4, 3): [1, 0, 0, 0], (4, 4): [0, 0, 0, 1], (4, 5): [1, 0, 0, 0], (4, 6): [0, 0, 0, 1], (4, 7): [0, 0, 0, 1], (4, 8): [0, 0, 0, 1], (4, 9): [1, 0, 0, 0], (5, 0): [1, 0, 0, 0], (5, 1): [1, 0, 0, 0], (5, 2): [1, 0, 0, 0], (5, 3): [1, 0, 0, 0], (5, 4): [0, 0, 0, 1], (5, 5): [1, 0, 0, 0], (5, 6): [1, 0, 0, 0], (5, 7): [0, 0, 0, 1], (5, 8): [0, 0, 0, 1], (5, 9): [1, 0, 0, 0], (6, 0): [0, 0, 0, 1], (6, 1): [1, 0, 0, 0], (6, 2): [1, 0, 0, 0], (6, 3): [1, 0, 0, 0], (6, 4): [1, 0, 0, 0], (6, 5): [1, 0, 0, 0], (6, 6): [1, 0, 0, 0], (6, 7): [1, 0, 0, 0], (6, 8): [1, 0, 0, 0], (6, 9): [1, 0, 0, 0], (7, 0): [0, 0, 0, 1], (7, 1): [0, 0, 0, 1], (7, 2): [0, 0, 0, 1], (7, 3): [0, 0, 0, 1], (7, 4): [0, 0, 0, 1], (7, 5): [0, 0, 0, 1], (7, 6): [0, 0, 0, 1], (7, 7): [0, 0, 0, 1], (7, 8): [1, 0, 0, 0], (7, 9): [1, 0, 0, 0], (8, 0): [0, 0, 0, 1], (8, 1): [0, 0, 0, 1], (8, 2): [0, 0, 0, 1], (8, 3): [0, 0, 0, 1], (8, 4): [0, 0, 0, 1], (8, 5): [0, 0, 0, 1], (8, 6): [0, 0, 0, 1], (8, 7): [0, 0, 0, 1], (8, 8): [0, 0, 0, 1], (8, 9): [1, 0, 0, 0], (9, 0): [0, 0, 0, 1], (9, 1): [0, 0, 0, 1], (9, 2): [0, 0, 0, 1], (9, 3): [0, 0, 0, 1], (9, 4): [0, 0, 0, 1], (9, 5): [0, 0, 0, 1], (9, 6): [0, 0, 0, 1], (9, 7): [0, 0, 0, 1], (9, 8): [0, 0, 0, 1], (9, 9): [1, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# policy iteration algorithm \n",
    "for i in range(1,2):\n",
    "    print(\"########### Iteration number: \",i)   \n",
    "    Vpi=policy_evaluation(pi,V,iteration_num=2)\n",
    "    pi=policy_improvement(Vpi)\n",
    "\n",
    "print(np.array(Vpi))\n",
    "\n",
    "print(pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c035fe6-5d8e-457f-94ea-c16e731e619a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(1, 0)\n",
      "reward is:  -1\n",
      "terminated: False\n",
      "0\n",
      "(2, 0)\n",
      "reward is:  -1\n",
      "terminated: False\n",
      "0\n",
      "(3, 0)\n",
      "reward is:  -1\n",
      "terminated: False\n",
      "3\n",
      "(3, 1)\n",
      "reward is:  -1\n",
      "terminated: False\n",
      "0\n",
      "(4, 1)\n",
      "reward is:  -1\n",
      "terminated: False\n",
      "0\n",
      "(5, 1)\n",
      "reward is:  -1\n",
      "terminated: False\n",
      "0\n",
      "(6, 1)\n",
      "reward is:  -1\n",
      "terminated: False\n",
      "0\n",
      "(7, 1)\n",
      "reward is:  -1\n",
      "terminated: False\n",
      "3\n",
      "(7, 2)\n",
      "reward is:  -1\n",
      "terminated: False\n",
      "3\n",
      "(7, 3)\n",
      "reward is:  -1\n",
      "terminated: False\n",
      "3\n",
      "(7, 4)\n",
      "reward is:  -1\n",
      "terminated: False\n",
      "3\n",
      "(7, 5)\n",
      "reward is:  -1\n",
      "terminated: False\n",
      "3\n",
      "(7, 6)\n",
      "reward is:  -1\n",
      "terminated: False\n",
      "3\n",
      "(7, 7)\n",
      "reward is:  -1\n",
      "terminated: False\n",
      "3\n",
      "(7, 8)\n",
      "reward is:  -1\n",
      "terminated: False\n",
      "0\n",
      "(8, 8)\n",
      "reward is:  -1\n",
      "terminated: False\n",
      "3\n",
      "(8, 9)\n",
      "reward is:  -1\n",
      "terminated: False\n",
      "0\n",
      "(9, 9)\n",
      "reward is:  0\n",
      "terminated: True\n",
      "total rewards:  -17\n",
      "The end\n"
     ]
    }
   ],
   "source": [
    "# The loop below will test the policy iteration algorithm\n",
    "# start position\n",
    "gw.reset()\n",
    "o=(0,0,dim-1,dim-1)\n",
    "terminated=False\n",
    "rewards=[]\n",
    "while not terminated:\n",
    "\n",
    "    a=sample_categorical(pi[o[:2]])\n",
    "    print(a)\n",
    "    o,r,terminated,_,_,=gw.step(a)\n",
    "    rewards.append(r)\n",
    "    gw.render(np.round(Vpi, 1),mode='human')\n",
    "    print(o[:2])\n",
    "    print(\"reward is: \",r)\n",
    "    print(\"terminated:\",terminated)\n",
    "\n",
    "print(\"total rewards: \", np.sum(rewards))\n",
    "\n",
    "print(\"The end\")\n",
    "pygame.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
