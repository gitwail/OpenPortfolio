{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e399d59-2036-40e7-8b9e-e892a4a5a3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x23c399ca290>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a97f1be-edfa-4fa7-8a87-148306725b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMcell():\n",
    "    def __init__(self,x_dim,hidden_dim,batch_size) -> None:\n",
    "        # hidden layer\n",
    "        self.ht_1=torch.rand((batch_size,hidden_dim))\n",
    "        concat_dim=hidden_dim+x_dim\n",
    "\n",
    "        \n",
    "        # forget gate \n",
    "        self.Wf=torch.rand((hidden_dim, concat_dim), requires_grad=True)\n",
    "        self.bf=torch.rand((hidden_dim,batch_size),requires_grad=True)\n",
    "\n",
    "        # input gate layer\n",
    "        self.Wi=torch.rand((hidden_dim, concat_dim), requires_grad=True)\n",
    "        self.bi=torch.rand((hidden_dim,batch_size),requires_grad=True)\n",
    "\n",
    "        # candidate layer\n",
    "        self.Wc=torch.rand((hidden_dim, concat_dim), requires_grad=True)\n",
    "        self.bc=torch.rand((hidden_dim,batch_size),requires_grad=True)\n",
    "\n",
    "        #output layer\n",
    "        self.Wo=torch.rand((hidden_dim, concat_dim), requires_grad=True)\n",
    "        self.bo=torch.rand((hidden_dim,batch_size),requires_grad=True)\n",
    "\n",
    "        # cell state\n",
    "        self.ct_1=torch.rand((hidden_dim,batch_size))\n",
    "\n",
    "    def forward(self,xt):\n",
    "        Xt=torch.concat([self.ht_1,xt],axis=1)\n",
    "        # forget gate\n",
    "        ft=torch.sigmoid((self.Wf@Xt.T)+self.bf)\n",
    "        # input gate \n",
    "        it=torch.sigmoid((self.Wi@Xt.T)+self.bi)\n",
    "        # candidate state\n",
    "        c_tild=torch.tanh((self.Wc@Xt.T)+self.bc)\n",
    "        # state calculation ct\n",
    "        ct=(ft*self.ct_1)+(it*c_tild)\n",
    "        # output gate of ct\n",
    "        ot=torch.sigmoid((self.Wo@Xt.T)+self.bo)\n",
    "        # new hidden layer\n",
    "        ht=ot*torch.tanh(ct)\n",
    "\n",
    "        return ht.T,ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f7b767-43d2-4b30-b525-16fe120cfc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9622, 0.9701, 0.9067, 0.9771]], grad_fn=<PermuteBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xt=torch.rand((20,1,3))\n",
    "\n",
    "cell=LSTMcell(x_dim=3,hidden_dim=4,batch_size=1)\n",
    "for x in xt:\n",
    "    ht,ct=cell.forward(x)\n",
    "    cell.ht_1=ht\n",
    "    cell.ct_1=ct\n",
    "   \n",
    "print(ht)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc96d579-0eb1-4f4e-9b5e-cea17c08dfcd",
   "metadata": {},
   "source": [
    "### Generating names using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d1f438-a757-4891-98dc-631e74c99ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
