{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10c60e69-de3a-40bc-9e52-ff05969ebc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 0, 9, 9), 'initialisation')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../lib/myenv\")\n",
    "from gridworld import gridworld\n",
    "import numpy as np \n",
    "import pygame\n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "# sample from categorical distribution\n",
    "def sample_categorical(probabilities):\n",
    "    return random.choices(range(len(probabilities)), probabilities)[0]\n",
    "\n",
    "# gridworld dimension\n",
    "dim=10\n",
    "# gamma discounting factor \n",
    "gamma=1\n",
    "\n",
    "# delta for policy evaluation\n",
    "delta=0\n",
    "\n",
    "#env variable \n",
    "gw=gridworld(dim)\n",
    "\n",
    "# State value (V) is an array of dimension nxn where n is the gridworld size\n",
    "V=np.random.rand(dim,dim)\n",
    "# V=np.zeros((dim,dim))\n",
    "\n",
    "\n",
    "#Transition matrix\n",
    "Pss=np.ones((dim,dim))\n",
    "\n",
    "# The action mapping for human readibility\n",
    "# 0:right\n",
    "# 1:Left\n",
    "# 2:UP\n",
    "# 3:Down \n",
    "\n",
    "# The agent is placed at (0,0) and value function are initiliazed to a zero array\n",
    "gw.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68ed6a39-1f51-4fed-8d74-07d3389b37c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(dim):\n",
    "    \"\"\"\n",
    "    Initial policy with 1/4 chance for each action\n",
    "    Input: dimension of gridworld\n",
    "    output: random uniform policy\n",
    "    \"\"\"\n",
    "    pi={}\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            pi[(i,j)]=[0.25]*4\n",
    "\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28b45e55-6598-4d69-9ee6-7b5bd5fad0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): [0.25, 0.25, 0.25, 0.25],\n",
       " (0, 1): [0.25, 0.25, 0.25, 0.25],\n",
       " (0, 2): [0.25, 0.25, 0.25, 0.25],\n",
       " (0, 3): [0.25, 0.25, 0.25, 0.25],\n",
       " (0, 4): [0.25, 0.25, 0.25, 0.25]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial random uniform policy\n",
    "pi=policy(dim)\n",
    "sliced_policy = dict(list(pi.items())[:5])\n",
    "sliced_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "542ad6ab-9bb8-4b2e-952c-2504140d1e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation(pi,V,iteration_num=1):\n",
    "    delta=0\n",
    "    #looping over all states\n",
    "    for _ in range(iteration_num):\n",
    "        Vc=V.copy()\n",
    "        for i in range(dim):\n",
    "            for j in range(dim):\n",
    "                gw.reset()\n",
    "                listupdate=[]\n",
    "                gw.agent=(i,j)\n",
    "\n",
    "                if (i,j)!=(0,0):\n",
    "                   for a in range(4):\n",
    "                        o,r,_,_,_,=gw.step(a)\n",
    "                        k,l=o[:2]\n",
    "                        listupdate.append(pi[(i,j)][a]*(r+(gamma*Vc[k,l])))\n",
    "                    \n",
    "                    #update Vk+1 ##### the update here max is different from policy iteration (mean\n",
    "                   Vc[i,j]=np.max(listupdate)\n",
    "                \n",
    "                #calculate delta\n",
    "                # print(\"state: \",(i,j))\n",
    "                # print(\"V\",V[i,j])\n",
    "                # print(\"Vc\",Vc[i,j])\n",
    "                # print(\"Vc-V\",np.abs(Vc[i,j]-V[i,j]))\n",
    "                # delta=max(delta,np.abs(V[i,j]-Vc[i,j]))\n",
    "                # print(\"delta \",delta)\n",
    "\n",
    "        \n",
    "        V=Vc\n",
    "        # if delta <0.1:\n",
    "        #     break\n",
    "\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2144a5d4-1963-4888-866f-cc65373d5e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(Vpi):\n",
    "# policy iteration \n",
    "    for i in range(dim):\n",
    "                for j in range(dim):\n",
    "                    listofall=[-100]*4\n",
    "                    r=-1\n",
    "                    if (i,j)==gw.target:\n",
    "                        r=0\n",
    "                    \n",
    "                    # listofall=[Vpi[i+1,j],Vpi[i-1,j],Vpi[i,j-1],Vpi[i,j+1]]\n",
    "                    if i+1<dim:\n",
    "                        listofall[0]=pi[(i,j)][0]*(r+(gamma*Vpi[i+1,j]))\n",
    "                    if j+1<dim:\n",
    "                        listofall[3]=pi[(i,j)][3]*(r+(gamma*Vpi[i,j+1])) \n",
    "                    if i-1>dim:\n",
    "                        listofall[1]=pi[(i,j)][1]*(r+(gamma*Vpi[i-1,j]))\n",
    "                    if j-1>dim:\n",
    "                        listofall[2]=pi[(i,j)][1]*(r+(gamma*Vpi[i,j-1]))\n",
    "\n",
    "\n",
    "                    a=np.argmax(listofall)\n",
    "\n",
    "                    pi[(i,j)]=[1 if i == a else 0 for i in range(4)]\n",
    "\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "790b1732-6bd4-44fe-b8ce-e0f06620c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# value iteration algo \n",
    "Vpi=policy_evaluation(pi,V,iteration_num=3)\n",
    "pi=policy_improvement(Vpi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ea18062-9d55-48e0-91a4-a4026abc7d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(1, 0)\n",
      "reward is:  -1\n",
      "3\n",
      "(1, 1)\n",
      "reward is:  -1\n",
      "0\n",
      "(2, 1)\n",
      "reward is:  -1\n",
      "0\n",
      "(3, 1)\n",
      "reward is:  -1\n",
      "0\n",
      "(4, 1)\n",
      "reward is:  -1\n",
      "0\n",
      "(5, 1)\n",
      "reward is:  -1\n",
      "0\n",
      "(6, 1)\n",
      "reward is:  -1\n",
      "0\n",
      "(7, 1)\n",
      "reward is:  -1\n",
      "0\n",
      "(8, 1)\n",
      "reward is:  -1\n",
      "3\n",
      "(8, 2)\n",
      "reward is:  -1\n",
      "0\n",
      "(9, 2)\n",
      "reward is:  -1\n",
      "3\n",
      "(9, 3)\n",
      "reward is:  -1\n",
      "3\n",
      "(9, 4)\n",
      "reward is:  -1\n",
      "3\n",
      "(9, 5)\n",
      "reward is:  -1\n",
      "3\n",
      "(9, 6)\n",
      "reward is:  -1\n",
      "3\n",
      "(9, 7)\n",
      "reward is:  -1\n",
      "3\n",
      "(9, 8)\n",
      "reward is:  -1\n",
      "3\n",
      "(9, 9)\n",
      "reward is:  0\n",
      "total rewards:  -17\n"
     ]
    }
   ],
   "source": [
    "# The loop below will test the policy iteration algorithm\n",
    "# start position\n",
    "gw.reset()\n",
    "o=(0,0,dim-1,dim-1)\n",
    "terminated=False\n",
    "rewards=[]\n",
    "while not terminated:\n",
    "\n",
    "    a=sample_categorical(pi[o[:2]])\n",
    "    print(a)\n",
    "    o,r,terminated,_,_,=gw.step(a)\n",
    "    rewards.append(r)\n",
    "    gw.render(np.round(Vpi, 3),mode='human')\n",
    "    print(o[:2])\n",
    "    print(\"reward is: \",r)\n",
    "\n",
    "print(\"total rewards: \", np.sum(rewards))\n",
    "\n",
    "pygame.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
